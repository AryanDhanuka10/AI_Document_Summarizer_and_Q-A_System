LLM_PROVIDER=groq # using groq for testing by default

# LLM Configuration
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-4o

GROQ_API_KEY=your_api_key_here
GROQ_MODEL=gpt-4o

LLM_PROVIDER=openai  # openai | groq

# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENV=your_pinecone_environment_here
# example: us-east-1-aws

# Backend
CHATBACKEND_URL=http://localhost:8000
